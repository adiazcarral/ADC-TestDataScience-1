{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d834ba6b",
   "metadata": {},
   "source": [
    "# Testing Notebook (Standalone)\n",
    "This notebook tests the trained model on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a61b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04eb001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Re-define model for loading\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(28*28, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.linear(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc59a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load test data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_set = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee37e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate function\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    return np.array(all_targets), np.array(all_preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d856d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    cm_percent = np.nan_to_num(cm_percent)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt=\".1f\", cmap=\"Blues\",\n",
    "                xticklabels=range(10), yticklabels=range(10))\n",
    "    plt.title(\"Confusion Matrix (%)\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a31c0cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, device)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_true,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_confusion_matrix\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name):\n\u001b[0;32m----> 2\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m[model_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[model_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m))  \u001b[38;5;66;03m# For MNIST: 0 to 9\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'results'"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LogisticRegression()\n",
    "model.load_state_dict(torch.load(\"logistic.pth\", map_location=device))\n",
    "model.to(device)\n",
    "y_true, y_pred = evaluate_model(model, test_loader, device)\n",
    "plot_confusion_matrix(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846f0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(self, model_name):\n",
    "    y_true = self.results[model_name][\"true_labels\"]\n",
    "    y_pred = self.results[model_name][\"pred_labels\"]\n",
    "    labels = list(range(10))  # For MNIST: 0 to 9\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    # Normalize rows (true labels) to percentages\n",
    "    cm_percent = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True) * 100\n",
    "    cm_percent = np.nan_to_num(cm_percent)  # avoid NaNs for any empty rows\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cm_percent, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.ax.set_ylabel(\"Percentage (%)\", rotation=-90, va=\"bottom\")\n",
    "\n",
    "        # Set labels\n",
    "    ax.set(\n",
    "    xticks=np.arange(len(labels)),\n",
    "    yticks=np.arange(len(labels)),\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    xlabel=\"Predicted label\",\n",
    "    ylabel=\"True label\",\n",
    "    title=f\"Confusion Matrix (%) - {model_name}\"\n",
    "    )\n",
    "\n",
    "    # Rotate tick labels\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Annotate each cell with percentage\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            percentage = cm_percent[i, j]\n",
    "            ax.text(\n",
    "                j, i, f\"{percentage:.1f}\",\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if percentage > 50 else \"black\"\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc801a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
